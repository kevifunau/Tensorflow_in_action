{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "pd.set_option(\"max_columns\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 784) (37800,) (4200, 784) (4200,)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "train_data = pd.read_csv(\"data/train.csv\",sep =\",\")\n",
    "test_data = pd.read_csv(\"data/test.csv\",sep = \",\")\n",
    "Y = data[\"label\"]\n",
    "X = data.iloc[:,1:]\n",
    "tr_data_x, ts_data_x,tr_data_y,ts_data_y = train_test_split(X,Y,test_size=0.1)\n",
    "print(tr_data_x.shape,tr_data_y.shape,ts_data_x.shape,ts_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 28, 28, 1) (4200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "tr_data_x = tr_data_x.values.reshape([-1,28,28,1])\n",
    "ts_data_x = ts_data_x.values.reshape([-1,28,28,1])\n",
    "print(tr_data_x.shape,ts_data_x.shape)\n",
    "# onehotencoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit([[i] for i in range(10)])\n",
    "tr_data_y  = enc.transform(tr_data_y.values.reshape(-1,1)).toarray()\n",
    "ts_data_y = enc.transform(ts_data_y.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建CNN 网络架构\n",
    "X = tf.placeholder(\"float\",[None,28,28,1])\n",
    "Y = tf.placeholder(\"float\",[None,10])\n",
    "keep_conv = tf.placeholder(\"float\")\n",
    "keep_hidden = tf.placeholder(\"float\")\n",
    "# 初始化权重W \n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.01,dtype=np.float32))\n",
    "# init bias\n",
    "def init_bias(shape):\n",
    "    return tf.constant(0.,shape = shape,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_28:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_21:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##### first layer\n",
    "## convolution\n",
    "w1 = init_weights([3,3,1,32])\n",
    "b1 = init_bias([32])\n",
    "l1 = tf.nn.conv2d(X,w1,[1,1,1,1],padding=\"SAME\") + b1\n",
    "l1_act = tf.nn.relu(l1)\n",
    "print(l1_act)\n",
    "## pooling\n",
    "l1_act_pool = tf.nn.max_pool(l1_act,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "print(l1_act_pool)\n",
    "## dropout\n",
    "l1_act_pool_dropout = tf.nn.dropout(l1_act_pool,keep_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_29:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_22:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##### second layer\n",
    "## convolution\n",
    "w2 = init_weights([3,3,32,64])\n",
    "b2 = init_bias([64])\n",
    "l2 = tf.nn.conv2d(l1_act_pool_dropout,w2,[1,1,1,1],padding=\"SAME\") + b2\n",
    "l2_act = tf.nn.relu(l2)\n",
    "print(l2_act)\n",
    "## pooling\n",
    "l2_act_pool = tf.nn.max_pool(l2_act,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "print(l2_act_pool)\n",
    "## dropout\n",
    "l2_act_pool_dropout = tf.nn.dropout(l2_act_pool,keep_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_30:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
      "Tensor(\"MaxPool_23:0\", shape=(?, 4, 4, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##### third layer\n",
    "## convolution\n",
    "w3 = init_weights([3,3,64,128])\n",
    "b3 = init_bias([128])\n",
    "l3 = tf.nn.conv2d(l2_act_pool_dropout,w3,[1,1,1,1],padding=\"SAME\") + b3\n",
    "l3_act = tf.nn.relu(l3)\n",
    "print(l3_act)\n",
    "## pooling\n",
    "l3_act_pool = tf.nn.max_pool(l3_act,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "print(l3_act_pool)\n",
    "## dropout\n",
    "l3_act_pool_dropout = tf.nn.dropout(l3_act_pool,keep_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### fc layer \n",
    "w4 = init_weights([128 * 4 * 4, 625])\n",
    "b4  = init_bias([625])\n",
    "l4 = tf.matmul(tf.reshape(l3_act_pool_dropout,[-1,w4.get_shape().as_list()[0]]),w4) + b4\n",
    "l4_act = tf.nn.relu(l4)\n",
    "l4_act_dropout = tf.nn.dropout(l4_act,keep_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_16:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### output layer\n",
    "w_o = init_weights([l4_act_dropout.get_shape().as_list()[-1],10])\n",
    "b_o = init_bias([10])\n",
    "l_o = tf.matmul(l4_act_dropout,w_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=l_o,labels=Y))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001,0.9).minimize(cost)\n",
    "predict_op = tf.argmax(l_o,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination\n",
    "batch = 128\n",
    "test_size = 256\n",
    "### training\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(20):\n",
    "        training_batch = zip(range(0,len(tr_data_x),batch),range(batch,len(tr_data_x)+1,batch))\n",
    "        \n",
    "        for start ,end in training_batch:\n",
    "            print(start,end)\n",
    "            sess.run(train_op,feed_dict={X:tr_data_x,Y:tr_data_y,keep_conv :0.8,keep_hidden :0.5 })\n",
    "\n",
    "        # 随机采样test_size 个 测试样例\n",
    "        test_indices = np.arange(len(ts_data_x))\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:test_size]\n",
    "\n",
    "        print(i,np.mean(np.argmax(ts_data_y[test_indices],axis=1) == \\\n",
    "                        sess.run(predict_op,feed_dict={X:ts_data_x[test_indices],keep_conv : 1.0,keep_hidden: 1.0})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
