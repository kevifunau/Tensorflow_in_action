{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['user_id','item_id','rating','timestamp']\n",
    "df = pd.read_csv(\"ml-100k/u.data\",sep = '\\t',names = header)\n",
    "#  读取 100000 行 user -item -rating 的数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(n_users,n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按 90% 训练集 10% 的测试集 拆分数据\n",
    "train_data,test_data = map (np.array, train_test_split(df,test_size = 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 10\n",
    "batch_size = 200\n",
    "# 搭建NN\n",
    "user_id = tf.placeholder(tf.int32,[batch_size])\n",
    "item_id = tf.placeholder(tf.int32,[batch_size])\n",
    "rate = tf.placeholder(tf.float64,[batch_size,1])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeding = tf.Variable(tf.random_uniform([n_users+1,\\\n",
    "                        embedding_size]),trainable = True)\n",
    "\n",
    "item_embeding = tf.Variable(tf.random_uniform([n_items+1,\\\n",
    "                        embedding_size]),trainable = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tf.nn.embedding_lookup(user_embeding,user_id)\n",
    "item_input = tf.nn.embedding_lookup(item_embeding,item_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_input = tf.multiply(user_input,item_input)\n",
    "# 我们定义 第一层 100 个神经元  200 * 10 * 10 *100 + 【100】 = 200 * 100\n",
    "# w_1 初始值 按高斯分布去\n",
    "# bias 初始值为 0\n",
    "w_1 = tf.Variable(tf.truncated_normal([embedding_size,100],stddev=0.1))\n",
    "b_1 = tf.Variable(tf.constant(0.,shape=[100]))\n",
    "l_1 = tf.nn.relu(tf.nn.xw_plus_b(fc_input,w_1,b_1))\n",
    "# 以keep_prob的概率 扔掉 神经元\n",
    "l_1_drop = tf.nn.dropout(l_1,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层 50个神经元  200 *100 * 100 *50 + 【50】 = 200 * 50\n",
    "w_2 = tf.Variable(tf.truncated_normal([100,50],stddev=0.1))\n",
    "b_2 = tf.Variable(tf.constant(0.,shape=[50]))\n",
    "l_2 = tf.nn.relu(tf.nn.xw_plus_b(l_1_drop,w_2,b_2))\n",
    "l_2_drop = tf.nn.dropout(l_2,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出层 一个神经元 200 * 50 * 50 * 1 + 【1】 = 200 *1 \n",
    "w_3 = tf.Variable(tf.truncated_normal([50,1],stddev=0.1))\n",
    "b_3 = tf.Variable(tf.constant(0.,shape =[1]))\n",
    "prediction = tf.nn.relu(tf.nn.xw_plus_b(l_2_drop,w_3,b_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 MSE \n",
    "loss = tf.losses.mean_squared_error(rate,prediction)\n",
    "# Adam优化 学习率 0.001\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning\n",
      "epoch:0\n",
      "1.2214755462973774\n",
      "loss: 2.761, rmse:1.105\n",
      "epoch:1\n",
      "1.112986017795254\n",
      "loss: 1.596, rmse:1.055\n",
      "epoch:2\n",
      "1.0301056700581321\n",
      "loss: 1.431, rmse:1.015\n",
      "epoch:3\n",
      "0.9745297240938611\n",
      "loss: 1.309, rmse:0.987\n",
      "epoch:4\n",
      "0.9580527728470296\n",
      "loss: 1.233, rmse:0.979\n",
      "epoch:5\n",
      "0.9451448430011485\n",
      "loss: 1.172, rmse:0.972\n",
      "epoch:6\n",
      "0.9369008225011338\n",
      "loss: 1.122, rmse:0.968\n",
      "epoch:7\n",
      "0.9380395396859423\n",
      "loss: 1.083, rmse:0.969\n",
      "epoch:8\n",
      "0.9272159787774171\n",
      "loss: 1.043, rmse:0.963\n",
      "epoch:9\n",
      "0.9248870234397868\n",
      "loss: 1.013, rmse:0.962\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"start learning\")\n",
    "    for epoch in range(10):\n",
    "        print(\"epoch:{}\".format(epoch))\n",
    "        train_loss = []\n",
    "        for start,end in zip(range(0,len(train_data),batch_size),range(batch_size,len(train_data),batch_size)):\n",
    "            tr_loss,_ = sess.run([loss, train], feed_dict={user_id : train_data[start:end,0], item_id : train_data[start:end,1], rate: train_data[start:end,2].reshape(batch_size,1), keep_prob: 0.5})\n",
    "            train_loss.append(tr_loss)\n",
    "        # test \n",
    "        rmse=[]\n",
    "        for start,end in zip(range(0,len(test_data),batch_size),range(batch_size,len(test_data),batch_size)):\n",
    "            pred = sess.run(prediction, feed_dict={user_id : test_data[start:end,0], item_id : test_data[start:end,1], keep_prob: 1.0})\n",
    "            pred=np.array([ [min(max(i[0],1),5)] for i in pred])\n",
    "            rmse.append((pred - test_data[start:end,2].reshape(batch_size,1))**2)\n",
    "        print(np.mean(rmse))\n",
    "        print(\"loss: {:.3f}, rmse:{:.3f}\".format(np.mean(train_loss),np.sqrt(np.mean(rmse))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
